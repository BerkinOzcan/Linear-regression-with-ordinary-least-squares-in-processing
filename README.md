# Linear-regression-with-ordinary-least-squares-in-processing
This Processing project demonstrates linear regression with ordinary least squares. You can add data points by tapping your mouse
This is only the source code. You are going to need Processing IDE to run this code and see the results.
Processing website: https://processing.org/
# Screenshot
<img src="/ssforlinearreg/ss1.png?raw=true" width="480">

# Formulas and stuff!
/*!)-*&~n/{"isRoot":false,"isTextMode":false,"isTabularCellsSelected":false,"isPureText":false,"insideInlineMath":false,"lines":[{"blocks":[{"text":"m="},{"text":"\\frac","type":"composite","elements":{"value":{"lines":[{"blocks":[{"text":"ùõ¥"},{"type":"single","text":"("},{"text":"x-"},{"text":"\\overline","type":"composite","elements":{"value":{"lines":[{"blocks":[{"text":"x"},{"type":"single","text":")"}]}]}}},{"text":"+"},{"type":"single","text":"("},{"text":"y-"},{"text":"\\overline","type":"composite","elements":{"value":{"lines":[{"blocks":[{"text":"y"}]}]}}},{"type":"single","text":")"}]}]},"sub1":{"lines":[{"blocks":[{"text":"ùõ¥"},{"type":"single","text":"("},{"text":"x-"},{"text":"\\overline","type":"composite","elements":{"value":{"lines":[{"blocks":[{"text":"x"}]}]}}},{"type":"single","text":")"},{"text":"\\power","type":"composite","elements":{"powerValue":{"lines":[{"blocks":[{"text":"2"}]}]}}}]}]}}},{"text":" "}],"tagInfo":{"type":"auto","tagId":"tid0.13283294711802052","tagName":""}}],"rootEditorId":"r0.7319431647829076","inlineMathDisplayStyle":null}

<img src="https://cdn.technologynetworks.com/tn/images/body/juuu1538567366342.pngraw=true" width="720">



A line's equation is y=mx+b. m is slope and b is the y intercept.
In the image above is the formula to calculate b value.
x's and y's with lines above them are avarage values (mean values)     sum of all values divided by how many there are.


